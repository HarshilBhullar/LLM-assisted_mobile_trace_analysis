{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='INSERT_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling the API...\n",
      "Python code has been saved to analyzer.py\n"
     ]
    }
   ],
   "source": [
    "sample_prompt = \"Write an mobileinsight analyzer to calculate how many MCC/MNC changes occurred per minute in the log.\\\n",
    "      NOTE: DO NOT WRITE ANY OTHER TEXT IN THE OUTPUT EXCEPT THE CODE. THE OUTPUT SHOULD BE ABLE TO BE RUN OUT OF THE BOX.\"\n",
    "\n",
    "print(\"Calling the API...\")\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  messages=[{\"role\": \"system\", \"content\": \"You are writing pythonscripts for the open-source project mobileinsight. \\\n",
    "      You will write scripts to analyze operational traces collected from 5G devices. Given a natural language \\\n",
    "     prompt or problem, you will write a python-script that analyzes 5G logs based on the problem. \\\n",
    "     Here is an example prompt: 'Write a Python script that reads and replays a log file specified by a command-line argument, \\\n",
    "     analyzes LTE downlink retransmissions from the log file, calculates the average MAC layer retransmission delay and the \\\n",
    "     average RLC layer retransmission delay, and then prints the calculated average delays. ' The expected output would be: \\\n",
    "    import sys \\n\\\n",
    "from mobile_insight.monitor import OfflineReplayer \\n\\\n",
    "from mobile_insight.analyzer import LteDlRetxAnalyzer \\n\\\n",
    "if __name__ == \\\"__main__\\\": \\n\\\n",
    "    src = OfflineReplayer() \\n\\\n",
    "    src.set_input_path(sys.argv[1]) \\n\\\n",
    "    lteAnalyzer = LteDlRetxAnalyzer() \\n\\\n",
    "    lteAnalyzer.set_source(src) \\n\\\n",
    "    src.run() \\n\\\n",
    "    mac_delay = 0.0 \\n\\\n",
    "    mac_delay_sample = 0 \\n\\\n",
    "    rlc_delay = 0.0 \\n\\\n",
    "    rlc_delay_sample = 0 \\n\\\n",
    "    for _, bearer in lteAnalyzer.bearer_entity.items(): \\n\\\n",
    "        for item in bearer.mac_retx: \\n\\\n",
    "            mac_delay += item['mac_retx'] \\n\\\n",
    "        mac_delay_sample += len(bearer.mac_retx) \\n\\\n",
    "        for item in bearer.rlc_retx: \\n\\\n",
    "            rlc_delay += item['rlc_retx'] \\n\\\n",
    "        rlc_delay_sample += len(bearer.rlc_retx) \\n\\\n",
    "    avg_mac_delay = float(mac_delay) / mac_delay_sample if mac_delay_sample > 0 else 0.0 \\n\\\n",
    "    avg_rlc_delay = float(rlc_delay) / rlc_delay_sample if rlc_delay_sample > 0 else 0.0 \\n\\\n",
    "    print(\\\"Average MAC retx delay is: \\\", avg_mac_delay) \\n\\\n",
    "    print(\\\"Average RLC retx delay is:\\\", avg_rlc_delay)\"},\n",
    "    {\"role\": \"user\", \"content\": sample_prompt}]\n",
    ")\n",
    "\n",
    "analyzer_code = str(response.choices[0].message.content)\n",
    "\n",
    "analyzer_code = analyzer_code.replace(\"```python\", \"\", 1)\n",
    "analyzer_code = analyzer_code.replace(\"```\", \"\", 1)\n",
    "\n",
    "file_name= \"analyzer.py\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(analyzer_code)\n",
    "\n",
    "print(f\"Python code has been saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 10\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are writing python scripts for the open-source project Mobileinsight. You will write scripts to analyze operational traces collected from 5G devices. Given a natural language prompt or problem, you will write a python script that analyzes 5G logs based on the problem. NOTE: Do NOT write any other text in the output except the code. The output should be able to be run out of the box.'}\n",
      "{'role': 'user', 'content': \"I want you to define a class `myAnalyzer` that inherits from a base `Analyzer` class, and returns statistics for attach events: \\\\n. Class Definition: `myAnalyzer` \\\\nThe constructor initializes the `Analyzer` base class, sets up message counters for authentication requests, security commands, attach accepts, attach requests, and attach rejections. \\\\nThe class should read in incoming and outgoing NAS ESM and EMM packets. \\\\nThe `__msg_callback` function processes each message by decoding the data and examining XML content to identify specific NAS message types like attach requests, attach accepts, attach rejections, authentication requests, and security mode commands. It updates the respective counters. \\\\n\\\\n2. Analysis Function: `my_analysis` \\\\nInitialize an `OfflineReplayer` as the data source, setting the input path for the trace logs. \\\\nConfigure the source with an instance of `myAnalyzer` and runs the analysis. It should include error handling to manage exceptions that might occur during execution, providing feedback if the analysis fails. \\\\n\\\\n3. Main Function:\\\\nAfter successfully running the analysis, the script gathers the counts of each event type from the analyzer.\\\\nIt compiles these statistics into a row format and appends them to a CSV file named 'attach_stats.csv'. This file logs the input file path and counts of authentication requests, security commands, attach accepts, attach requests, and attach rejections.\"}\n",
      "{'role': 'assistant', 'content': '#!/usr/bin/python\\n\\nimport sys\\nimport csv\\n\\nfrom mobile_insight.monitor import OfflineReplayer\\n\\n__all__ = [\"myAnalyzer\"]\\n\\ntry:\\n    import xml.etree.cElementTree as ET\\nexcept ImportError:\\n    import xml.etree.ElementTree as ET\\nfrom mobile_insight.analyzer.analyzer import *\\n\\n\\nimport time\\n\\n\\nclass myAnalyzer(Analyzer):\\n    def __init__(self):\\n        Analyzer.__init__(self)\\n        self.add_source_callback(self.__msg_callback)\\n        self.auth_count = 0\\n        self.security_count = 0\\n        self.attach_accept_count = 0\\n        self.attach_request_count = 0 #Outgoing\\n        self.attach_reject_count = 0\\n\\n    def set_source(self, source):\\n        \"\"\"\\n        Set the trace source. Enable the cellular signaling messages\\n\\n        :param source: the trace source (collector).\\n        \"\"\"\\n        Analyzer.set_source(self, source)\\n        source.enable_log(\"LTE_NAS_ESM_OTA_Incoming_Packet\")\\n        source.enable_log(\"LTE_NAS_ESM_OTA_Outgoing_Packet\")\\n        source.enable_log(\"LTE_NAS_EMM_OTA_Incoming_Packet\")\\n        source.enable_log(\"LTE_NAS_EMM_OTA_Outgoing_Packet\")\\n        # source.enable_log(\"LTE_RRC_OTA_Packet\")\\n        # source.enable_log_all()    \\n\\n    def reset_counter(self):\\n        self.auth_count = 0\\n        self.security_count = 0\\n        self.attach_accept_count = 0\\n        self.attach_request_count = 0\\n        self.attach_reject_count = 0 \\n\\n    def __msg_callback(self, msg):\\n        if msg.type_id == \"LTE_NAS_ESM_OTA_Incoming_Packet\" or msg.type_id == \"LTE_NAS_EMM_OTA_Incoming_Packet\":\\n            data = msg.data.decode()\\n            if \\'Msg\\' in data.keys():\\n                log_xml = ET.XML(data[\\'Msg\\'])\\n                #print(\\'x\\')\\n            else:\\n                return\\n            xml_msg = Event(msg.timestamp, msg.type_id, log_xml)\\n            for field in xml_msg.data.iter(\\'field\\'):\\n                if field.get(\\'name\\') != None and \\'nas_eps.nas_msg\\' in field.get(\\'name\\'):\\n                    if field.get(\\'showname\\') == \\'NAS EPS Mobility Management Message Type: Attach accept (0x42)\\':\\n                        self.attach_accept_count += 1\\n                    elif field.get(\\'showname\\') == \\'NAS EPS Mobility Management Message Type: Attach reject (0x44)\\':\\n                        self.attach_reject_count += 1\\n                    elif field.get(\\'showname\\') == \\'NAS EPS Mobility Management Message Type: Authentication request (0x52)\\':\\n                        self.auth_count += 1\\n                    elif field.get(\\'showname\\') == \\'NAS EPS Mobility Management Message Type: Security mode command (0x5d)\\':\\n                        self.security_count += 1\\n        elif msg.type_id == \"LTE_NAS_ESM_OTA_Outgoing_Packet\" or msg.type_id == \"LTE_NAS_EMM_OTA_Outgoing_Packet\":\\n            data = msg.data.decode()\\n            if \\'Msg\\' in data.keys():\\n                log_xml = ET.XML(data[\\'Msg\\'])\\n            else:\\n                return\\n            xml_msg = Event(msg.timestamp, msg.type_id, log_xml)\\n            for field in xml_msg.data.iter(\\'field\\'):\\n                if field.get(\\'name\\') != None and \\'nas_eps.nas_msg\\' in field.get(\\'name\\'):\\n                    if field.get(\\'showname\\') == \\'NAS EPS Mobility Management Message Type: Attach request (0x41)\\':\\n                        self.attach_request_count += 1\\n                    \\n\\n\\ndef my_analysis(input_path):\\n\\n    src = OfflineReplayer()\\n    src.set_input_path(input_path)\\n\\n    analyzer = myAnalyzer()\\n    analyzer.set_source(src)\\n    try:\\n        src.run()\\n    except:\\n        print(\\'Failed:\\', input_path)\\n        return None\\n\\n    return analyzer\\n\\n\\ninput_path = sys.argv[1]\\nanalyzer = my_analysis(input_path)\\nif analyzer:\\n    row = [input_path, analyzer.auth_count, analyzer.security_count, analyzer.attach_accept_count, analyzer.attach_request_count, analyzer.attach_reject_count]\\n    with open(\\'attach_stats.csv\\', \\'a\\') as f:\\n        writer = csv.writer(f)\\n        writer.writerow(row)\\n'}\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\bhull\\Desktop\\CS 219\\finetuning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-IGJzXSyLBimX2iEIS3HxVnx5', bytes=54245, created_at=1716921762, filename='finetuning.json', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(r\"C:\\Users\\bhull\\Desktop\\CS 219\\finetuning.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-wEigwb5OZ7jQKrp0fJ9CvmOp', created_at=1716921766, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-V8HzDM5peJZTa4SfEaBpor1V', result_files=[], seed=625328433, status='validating_files', trained_tokens=None, training_file='file-oZxTHY1hf2bbsGg6UfbM2kbl', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-oZxTHY1hf2bbsGg6UfbM2kbl\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-hvVuhTiLQkFR2mMMbAp42Mt3', created_at=1716871273, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-9wSRfbVv95YdK3snGzRrKsuv', created_at=1716871270, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal::9Tiw2Bjt', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-aPGT5TGAUtDG8VzaOoHAu8iv', created_at=1716871270, level='info', message='Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal::9Tiw20N4:ckpt-step-90', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-UjiipFrqZZUzb4YjlD3I52RD', created_at=1716871270, level='info', message='Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal::9Tiw1JKh:ckpt-step-80', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-VdhtToVYfWdFFrybuMeVjdwV', created_at=1716871265, level='info', message='Step 100/100: training loss=0.25', object='fine_tuning.job.event', data={'step': 100, 'train_loss': 0.25126126408576965, 'total_steps': 100, 'train_mean_token_accuracy': 0.9199491739273071}, type='metrics'), FineTuningJobEvent(id='ftevent-I3CvHEIBvhYhgNPb7sjiQqPc', created_at=1716871264, level='info', message='Step 99/100: training loss=0.36', object='fine_tuning.job.event', data={'step': 99, 'train_loss': 0.35598015785217285, 'total_steps': 100, 'train_mean_token_accuracy': 0.9078694581985474}, type='metrics'), FineTuningJobEvent(id='ftevent-z5v9VlJ7tDuqnUXNOqka1Y6r', created_at=1716871262, level='info', message='Step 98/100: training loss=0.12', object='fine_tuning.job.event', data={'step': 98, 'train_loss': 0.12080488353967667, 'total_steps': 100, 'train_mean_token_accuracy': 0.9681978821754456}, type='metrics'), FineTuningJobEvent(id='ftevent-l7sfaUTlx6zQQSIvxh1r7dZC', created_at=1716871260, level='info', message='Step 97/100: training loss=0.01', object='fine_tuning.job.event', data={'step': 97, 'train_loss': 0.012609552592039108, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-MyqLAgKhCl7PM7GBOl84mw6R', created_at=1716871257, level='info', message='Step 96/100: training loss=0.03', object='fine_tuning.job.event', data={'step': 96, 'train_loss': 0.02963031269609928, 'total_steps': 100, 'train_mean_token_accuracy': 0.99071204662323}, type='metrics'), FineTuningJobEvent(id='ftevent-Hrsx1gYgj0gLLLFJk5PeWIYH', created_at=1716871255, level='info', message='Step 95/100: training loss=0.17', object='fine_tuning.job.event', data={'step': 95, 'train_loss': 0.169389009475708, 'total_steps': 100, 'train_mean_token_accuracy': 0.9620991349220276}, type='metrics')], object='list', has_more=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-O6A3oJW2PAOMEN0yjJAq4AN2\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-O6A3oJW2PAOMEN0yjJAq4AN2\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "result = client.fine_tuning.jobs.list()\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)\n",
    "\n",
    "client.api_key = \"INSERT_HERE\"\n",
    "client.organization = \"INSERT_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python code has been saved to service_req_response_1.py\n"
     ]
    }
   ],
   "source": [
    "# service_req_stats prompt\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::9Tiw2Bjt\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are writing python scripts for the open-source project Mobileinsight. \\\n",
    "You will write scripts to analyze operational traces collected from 5G devices. Given a natural language \\\n",
    "prompt or problem, you will write a python script that analyzes 5G logs based on the problem. NOTE: Do NOT write any other text in the output except the code. The output should be able to be run out of the box.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I want you to define a class `myAnalyzer` that inherits from a base `Analyzer` class, and returns statistics for control plane service requests:\\\n",
    "\\\n",
    "1. Class Definition: `myAnalyzer`\\\n",
    "   - The class should read in LTE_NAS_EMM_OTA_Incoming_Packet, LTE_NAS_EMM_OTA_Outgoing_Packet and LTE_RRC_OTA_Packet.\\\n",
    "   - The class should initialize counters for various events: service rejections, service accepts, control plane service requests, and RRC releases.\\\n",
    "   - Registers a callback method (`__msg_callback`) to process incoming messages. For NAS EMM packets (both incoming and outgoing), it parses XML data to check specific NAS message types (Attach accept, Service accept, Service reject, and Control plane service request) and updates respective counters based on the contents. For RRC packets, it prints 'log_msg_len' and 'timestamp' data fields, if present.\\\n",
    "\\\n",
    "2. Analysis Function: `my_analysis`\\\n",
    "   - Creates an instance of an offline replay source (`OfflineReplayer`) for processing log files.\\\n",
    "   - Sets the file path for the input data and configures the source with the `myAnalyzer` instance.\\\n",
    "   - Runs the analysis by processing the trace data through the source. Any exceptions during this process are caught and reported.\\\n",
    "   - Returns the configured and used analyzer instance for further use or querying of the collected data.\\\n",
    "\\\n",
    "3. Main Function:\\\n",
    "    - The script is expected to be executed with a command-line argument specifying the path to the input log file.\\\n",
    "    - Upon successful analysis, it prints the count of RRC releases.\\\n",
    "    - If there are any control plane service requests and at least one service response (accept or reject), it appends these statistics along with the input file path to a CSV file for record-keeping.\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "analyzer_code = str(completion.choices[0].message.content)\n",
    "\n",
    "analyzer_code = analyzer_code.replace(\"```python\", \"\", 1)\n",
    "analyzer_code = analyzer_code.replace(\"```\", \"\", 1)\n",
    "\n",
    "file_name= \"service_req_response_1.py\"\n",
    "  \n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(analyzer_code)\n",
    "\n",
    "print(f\"Python code has been saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python code has been saved to attach_stats_response_1.py\n"
     ]
    }
   ],
   "source": [
    "# attach_stats prompt\n",
    "\n",
    "with open(r\"C:\\Users\\bhull\\Desktop\\CS 219\\testcases\\attach_stats\\input copy.txt\", \"r\") as file:\n",
    "    user_prompt = file.read().replace(\"\\n\", \" \") # replace newline with space\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::9Tiw2Bjt\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are writing python scripts for the open-source project Mobileinsight. \\\n",
    "You will write scripts to analyze operational traces collected from 5G devices. Given a natural language \\\n",
    "prompt or problem, you will write a python script that analyzes 5G logs based on the problem. NOTE: Do NOT write any other text in the output except the code. The output should be able to be run out of the box.\"},\n",
    "    {\"role\": \"user\", \"content\": user_prompt\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "analyzer_code = str(completion.choices[0].message.content)\n",
    "\n",
    "analyzer_code = analyzer_code.replace(\"```python\", \"\", 1)\n",
    "analyzer_code = analyzer_code.replace(\"```\", \"\", 1)\n",
    "\n",
    "file_name= \"attach_stats_response_1.py\"\n",
    "  \n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(analyzer_code)\n",
    "\n",
    "print(f\"Python code has been saved to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
