{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_basline.csv\n"
     ]
    }
   ],
   "source": [
    "### OUTER Baseline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def create_evaluation_dataset(target_folder, actual_output_folder, output_csv, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_generated_ICL.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Load in-context examples\n",
    "\n",
    "        # Construct the input by concatenating in-context examples and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for outer analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        I will give the main target prompt that you need to follow in order to generate an outer analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "        input_text += f\"Target Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_working_dataset'       # Folder with target prompts and expected outputs\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_basline.csv'             # Output CSV file path\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_analyzers_baseline'\n",
    "\n",
    "create_evaluation_dataset(target_folder, actual_output_folder, output_csv, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_baseline.csv\n"
     ]
    }
   ],
   "source": [
    "### INNER Baseline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def create_evaluation_dataset(target_folder, actual_output_folder, output_csv, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_baseline.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Load in-context examples\n",
    "\n",
    "        # Construct the input by concatenating in-context examples and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for inner analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        I will give the main target prompt that you need to follow in order to generate an inner analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "        input_text += f\"Target Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_working_dataset'       # Folder with target prompts and expected outputs\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_baseline.csv'             # Output CSV file path\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_analyzers_baseline'\n",
    "\n",
    "create_evaluation_dataset(target_folder, actual_output_folder, output_csv, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_ICL.csv\n"
     ]
    }
   ],
   "source": [
    "### INNER ICL\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "def load_in_context_examples(example_folder, n=3):\n",
    "    examples = []\n",
    "\n",
    "    # Get lists of .txt and .py files\n",
    "    txt_files = [f for f in os.listdir(example_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "    py_files = [f for f in os.listdir(example_folder) if f.startswith(\"modified_\") and f.endswith('.py')]\n",
    "\n",
    "    # Create a dictionary mapping base filenames to .py files\n",
    "    py_file_dict = {f.replace(\"modified_\", \"\").replace(\".py\", \"\"): f for f in py_files}\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        base_name = txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "        if base_name in py_file_dict:\n",
    "            txt_file_path = os.path.join(example_folder, txt_file)\n",
    "            py_file_path = os.path.join(example_folder, py_file_dict[base_name])\n",
    "\n",
    "            # Load the prompt + code from the .txt file\n",
    "            with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "                prompt_code = f.read().strip()\n",
    "\n",
    "            # Load the expected code from the .py file\n",
    "            with open(py_file_path, 'r', encoding='utf-8') as f:\n",
    "                expected_code = f.read().strip()\n",
    "\n",
    "            examples.append({\n",
    "                'prompt_code': prompt_code,\n",
    "                'expected_code': expected_code\n",
    "            })\n",
    "\n",
    "    # Randomly sample n examples\n",
    "    return random.sample(examples, min(n, len(examples)))\n",
    "\n",
    "def create_evaluation_dataset(example_folder, target_folder, actual_output_folder, output_csv, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_generated_ICL.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Load in-context examples\n",
    "        in_context_examples = load_in_context_examples(example_folder, n=n)\n",
    "\n",
    "        # Construct the input by concatenating in-context examples and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for inner analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        For context, I will be giving a few examples of a prompt + outer analyzer code pairs along with their corresponding expected inner analyzer code.\n",
    "\n",
    "        Then I will give the main target prompt that you need to follow in order to generate an inner analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "\n",
    "        for i, example in enumerate(in_context_examples):\n",
    "            input_text += f\"Example {i+1}:\\n{example['prompt_code']}\\n\\n Expected Output:\\n{example['expected_code']}\\n\\n\"\n",
    "\n",
    "        input_text += f\"Target Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "example_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_working_dataset'  # Folder with in-context examples\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_working_dataset'       # Folder with target prompts and expected outputs\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_ICL.csv'             # Output CSV file path\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_analyzers_ICL'\n",
    "\n",
    "create_evaluation_dataset(example_folder, target_folder, actual_output_folder, output_csv, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_ICL.csv\n"
     ]
    }
   ],
   "source": [
    "### OUTER ICL\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "def load_in_context_examples(example_folder, n=3):\n",
    "    examples = []\n",
    "\n",
    "    # Get lists of .txt and .py files\n",
    "    txt_files = [f for f in os.listdir(example_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "    py_files = [f for f in os.listdir(example_folder) if f.startswith(\"modified_\") and f.endswith('.py')]\n",
    "\n",
    "    # Create a dictionary mapping base filenames to .py files\n",
    "    py_file_dict = {f.replace(\"modified_\", \"\").replace(\".py\", \"\"): f for f in py_files}\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        base_name = txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "        if base_name in py_file_dict:\n",
    "            txt_file_path = os.path.join(example_folder, txt_file)\n",
    "            py_file_path = os.path.join(example_folder, py_file_dict[base_name])\n",
    "\n",
    "            # Load the prompt + code from the .txt file\n",
    "            with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "                prompt_code = f.read().strip()\n",
    "\n",
    "            # Load the expected code from the .py file\n",
    "            with open(py_file_path, 'r', encoding='utf-8') as f:\n",
    "                expected_code = f.read().strip()\n",
    "\n",
    "            examples.append({\n",
    "                'prompt_code': prompt_code,\n",
    "                'expected_code': expected_code\n",
    "            })\n",
    "\n",
    "    # Randomly sample n examples\n",
    "    return random.sample(examples, min(n, len(examples)))\n",
    "\n",
    "def create_evaluation_dataset(example_folder, target_folder, actual_output_folder, output_csv, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_generated_ICL.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Load in-context examples\n",
    "        in_context_examples = load_in_context_examples(example_folder, n=n)\n",
    "\n",
    "        # Construct the input by concatenating in-context examples and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for outer analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        For context, I will be giving a few examples of a prompt + inner analyzer code pairs along with their corresponding expected outer analyzer code.\n",
    "\n",
    "        Then I will give the main target prompt that you need to follow in order to generate an outer analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "\n",
    "        for i, example in enumerate(in_context_examples):\n",
    "            input_text += f\"Example {i+1}:\\n{example['prompt_code']}\\n\\n Expected Output:\\n{example['expected_code']}\\n\\n\"\n",
    "\n",
    "        input_text += f\"Target Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "example_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_working_dataset'  # Folder with in-context examples\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_working_dataset'       # Folder with target prompts and expected outputs\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_ICL.csv'             # Output CSV file path\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_analyzers_ICL'\n",
    "\n",
    "create_evaluation_dataset(example_folder, target_folder, actual_output_folder, output_csv, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhull\\AppData\\Local\\Temp\\ipykernel_5920\\3690642877.py:30: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "C:\\Users\\bhull\\AppData\\Local\\Temp\\ipykernel_5920\\3690642877.py:74: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(prompt_inner_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_RAG.csv\n"
     ]
    }
   ],
   "source": [
    "### INNER RAG\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# Step 1: Load and chunk the codebase, then create embeddings\n",
    "def index_codebase(directory):\n",
    "    # Load all .py files from the directory\n",
    "    loader = DirectoryLoader(\n",
    "        path=directory,\n",
    "        glob=\"**/*.py\",  # Only .py files\n",
    "        exclude=[\"**/__pycache__/**\", \"**/*.pyc\"]\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        separators=['\\n\\n', '\\n', ' ', '']\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Create embeddings for each chunk\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# Step 2: Load in-context examples\n",
    "def load_in_context_examples(example_folder, n=3):\n",
    "    examples = []\n",
    "\n",
    "    # Get lists of .txt and .py files\n",
    "    txt_files = [f for f in os.listdir(example_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "    py_files = [f for f in os.listdir(example_folder) if f.startswith(\"modified_\") and f.endswith('.py')]\n",
    "\n",
    "    # Create a dictionary mapping base filenames to .py files\n",
    "    py_file_dict = {f.replace(\"modified_\", \"\").replace(\".py\", \"\"): f for f in py_files}\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        base_name = txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "        if base_name in py_file_dict:\n",
    "            txt_file_path = os.path.join(example_folder, txt_file)\n",
    "            py_file_path = os.path.join(example_folder, py_file_dict[base_name])\n",
    "\n",
    "            # Load the prompt + code from the .txt file\n",
    "            with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "                prompt_code = f.read().strip()\n",
    "\n",
    "            # Load the expected code from the .py file\n",
    "            with open(py_file_path, 'r', encoding='utf-8') as f:\n",
    "                expected_code = f.read().strip()\n",
    "\n",
    "            examples.append({\n",
    "                'prompt_code': prompt_code,\n",
    "                'expected_code': expected_code\n",
    "            })\n",
    "\n",
    "    # Randomly sample n examples\n",
    "    return random.sample(examples, min(n, len(examples)))\n",
    "\n",
    "\n",
    "# Step 3: Retrieve relevant documents from the vector store\n",
    "def retrieve_relevant_documents(vectorstore, prompt_inner_code):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    relevant_docs = retriever.get_relevant_documents(prompt_inner_code)\n",
    "    retrieved_context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    return retrieved_context\n",
    "\n",
    "\n",
    "# Step 4: Create the evaluation dataset with retrieval context\n",
    "def create_evaluation_dataset_with_rag(example_folder, target_folder, actual_output_folder, output_csv, vectorstore, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_generated_RAG.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Retrieve relevant context using the vectorstore\n",
    "        retrieved_context = retrieve_relevant_documents(vectorstore, target_prompt_code)\n",
    "\n",
    "        # Load in-context examples\n",
    "        in_context_examples = load_in_context_examples(example_folder, n=n)\n",
    "\n",
    "        # Construct the input by concatenating in-context examples, retrieval context, and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for outer analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        For context, I will be giving a few examples of a prompt + inner analyzer code pairs along with their corresponding expected outer analyzer code.\n",
    "\n",
    "        Then, I will give relevant context of the codebase from my RAG to also aid in generating the outer analyzer.\n",
    "\n",
    "        Then I will give the main target prompt that you need to follow in order to generate an outer analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "\n",
    "        for i, example in enumerate(in_context_examples):\n",
    "            input_text += f\"Example {i+1}:\\n{example['prompt_code']}\\n\\nExpected Output:\\n{example['expected_code']}\\n\\n\"\n",
    "\n",
    "        input_text += f\"Relevant Context from codebase:\\n{retrieved_context}\\n\\nTarget Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code,\n",
    "            'retrieval_context': retrieved_context\n",
    "\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output', 'retrieval_context']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "example_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_working_dataset'\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_working_dataset'\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_outer_analyzers_RAG'\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\outer_dataset_RAG.csv'\n",
    "\n",
    "# Index the codebase and initialize the vectorstore\n",
    "codebase_directory = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\mobile_insight'\n",
    "vectorstore = index_codebase(codebase_directory)\n",
    "\n",
    "# Create the evaluation dataset\n",
    "create_evaluation_dataset_with_rag(example_folder, target_folder, actual_output_folder, output_csv, vectorstore, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created and saved to C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_RAG.csv\n"
     ]
    }
   ],
   "source": [
    "### INNER RAG\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# Step 1: Load and chunk the codebase, then create embeddings\n",
    "def index_codebase(directory):\n",
    "    # Load all .py files from the directory\n",
    "    loader = DirectoryLoader(\n",
    "        path=directory,\n",
    "        glob=\"**/*.py\",  # Only .py files\n",
    "        exclude=[\"**/__pycache__/**\", \"**/*.pyc\"]\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        separators=['\\n\\n', '\\n', ' ', '']\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Create embeddings for each chunk\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# Step 2: Load in-context examples\n",
    "def load_in_context_examples(example_folder, n=3):\n",
    "    examples = []\n",
    "\n",
    "    # Get lists of .txt and .py files\n",
    "    txt_files = [f for f in os.listdir(example_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "    py_files = [f for f in os.listdir(example_folder) if f.startswith(\"modified_\") and f.endswith('.py')]\n",
    "\n",
    "    # Create a dictionary mapping base filenames to .py files\n",
    "    py_file_dict = {f.replace(\"modified_\", \"\").replace(\".py\", \"\"): f for f in py_files}\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        base_name = txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "\n",
    "        if base_name in py_file_dict:\n",
    "            txt_file_path = os.path.join(example_folder, txt_file)\n",
    "            py_file_path = os.path.join(example_folder, py_file_dict[base_name])\n",
    "\n",
    "            # Load the prompt + code from the .txt file\n",
    "            with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "                prompt_code = f.read().strip()\n",
    "\n",
    "            # Load the expected code from the .py file\n",
    "            with open(py_file_path, 'r', encoding='utf-8') as f:\n",
    "                expected_code = f.read().strip()\n",
    "\n",
    "            examples.append({\n",
    "                'prompt_code': prompt_code,\n",
    "                'expected_code': expected_code\n",
    "            })\n",
    "\n",
    "    # Randomly sample n examples\n",
    "    return random.sample(examples, min(n, len(examples)))\n",
    "\n",
    "\n",
    "# Step 3: Retrieve relevant documents from the vector store\n",
    "def retrieve_relevant_documents(vectorstore, prompt_inner_code):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    relevant_docs = retriever.get_relevant_documents(prompt_inner_code)\n",
    "    retrieved_context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    return retrieved_context\n",
    "\n",
    "\n",
    "# Step 4: Create the evaluation dataset with retrieval context\n",
    "def create_evaluation_dataset_with_rag(example_folder, target_folder, actual_output_folder, output_csv, vectorstore, n=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Get all target prompt .txt files in the target folder\n",
    "    target_txt_files = [f for f in os.listdir(target_folder) if f.startswith(\"prompt_\") and f.endswith('.txt')]\n",
    "\n",
    "    for target_txt_file in target_txt_files:\n",
    "        target_base_name = target_txt_file.replace(\"prompt_\", \"\").replace(\".txt\", \"\")\n",
    "        target_txt_path = os.path.join(target_folder, target_txt_file)\n",
    "\n",
    "        # Find the corresponding expected output .py file\n",
    "        expected_py_file = f\"modified_{target_base_name}.py\"\n",
    "        expected_py_path = os.path.join(target_folder, expected_py_file)\n",
    "\n",
    "        # Find the corresponding actual output .py file\n",
    "        actual_output_file = f\"prompt_{target_base_name}_generated_RAG.py\"\n",
    "        actual_output_path = os.path.join(actual_output_folder, actual_output_file)\n",
    "\n",
    "        if not os.path.exists(expected_py_path):\n",
    "            print(f\"Expected output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(actual_output_path):\n",
    "            print(f\"Actual output file not found for {target_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load the target prompt code\n",
    "        with open(target_txt_path, 'r', encoding='utf-8') as f:\n",
    "            target_prompt_code = f.read().strip()\n",
    "\n",
    "        # Load the expected output code\n",
    "        with open(expected_py_path, 'r', encoding='utf-8') as f:\n",
    "            expected_output_code = f.read().strip()\n",
    "\n",
    "        # Load the actual output code\n",
    "        with open(actual_output_path, 'r', encoding='utf-8') as f:\n",
    "            actual_output_code = f.read().strip()\n",
    "\n",
    "        # Retrieve relevant context using the vectorstore\n",
    "        retrieved_context = retrieve_relevant_documents(vectorstore, target_prompt_code)\n",
    "\n",
    "        # Load in-context examples\n",
    "        in_context_examples = load_in_context_examples(example_folder, n=n)\n",
    "\n",
    "        # Construct the input by concatenating in-context examples, retrieval context, and the target prompt\n",
    "        input_text = \"\"\"\n",
    "        You are an AI assistant that generates code for inner analyzers using the Mobileinsight-core Python library, a library that enables below-IP, \\\n",
    "        fine-grained mobile network analytics on end devices. It is a cross-platform package for mobile network monitoring and analysis.\n",
    "\n",
    "        For context, I will be giving a few examples of a prompt + outer analyzer code pairs along with their corresponding expected inner analyzer code.\n",
    "\n",
    "        Then, I will give relevant context of the codebase from my RAG to also aid in generating the inner analyzer.\n",
    "\n",
    "        Then I will give the main target prompt that you need to follow in order to generate an inner analyzer.\n",
    "\n",
    "        NOTE: PLEASE PROVIDE ONLY THE CODE AND NOTHING ELSE, AS THIS OUTPUT IS BEING DIRECTLY SAVED TO A .PY FILE AND RAN AUTONOMOUSLY. \\\n",
    "        ADDITIONALLY, ENSURE THAT YOU PROVIDE THE FULL COMPLETE CODE, AND DO NOT LEAVE OUT ANY PARTS FOR THE USER TO COMPLETE. THE CODE SHOULD FULLY RUN \\\n",
    "        WITH NO ADDITIONAL MODIFICATIONS REQUIRED.\n",
    "        \"\"\"\n",
    "\n",
    "        for i, example in enumerate(in_context_examples):\n",
    "            input_text += f\"Example {i+1}:\\n{example['prompt_code']}\\n\\nExpected Output:\\n{example['expected_code']}\\n\\n\"\n",
    "\n",
    "        input_text += f\"Relevant Context from codebase:\\n{retrieved_context}\\n\\nTarget Prompt:\\n{target_prompt_code}\\n\"\n",
    "\n",
    "        # Add the input-output pair to the dataset\n",
    "        dataset.append({\n",
    "            'input': input_text,\n",
    "            'expected_output': expected_output_code,\n",
    "            'actual_output': actual_output_code,\n",
    "            'retrieval_context': retrieved_context\n",
    "\n",
    "        })\n",
    "\n",
    "    # Write the dataset to a CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['input', 'expected_output', 'actual_output', 'retrieval_context']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "\n",
    "    print(f\"Evaluation dataset created and saved to {output_csv}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "example_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_working_dataset'\n",
    "target_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_working_dataset'\n",
    "actual_output_folder = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\generated_inner_analyzers_RAG'\n",
    "output_csv = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\inner_dataset_RAG.csv'\n",
    "\n",
    "# Index the codebase and initialize the vectorstore\n",
    "codebase_directory = r'C:\\Users\\bhull\\Desktop\\UCLA Grad\\Spring 2024\\CS 219\\219_final_project\\LLM-assisted_mobile_trace_analysis\\mobile_insight'\n",
    "vectorstore = index_codebase(codebase_directory)\n",
    "\n",
    "# Create the evaluation dataset\n",
    "create_evaluation_dataset_with_rag(example_folder, target_folder, actual_output_folder, output_csv, vectorstore, n=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
